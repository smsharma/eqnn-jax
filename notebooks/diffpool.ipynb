{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import flax.linen as nn\n",
    "import jraph\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from models.gnn import GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1800, 4000, 3)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_nodes = 4000\n",
    "n_features = 3\n",
    "\n",
    "x_train = np.load(\"../../hierarchical-encdec/data/set_diffuser_data/train_halos.npy\")[:, :n_nodes, :n_features]\n",
    "x_train = x_train / 1000.\n",
    "\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "@partial(jax.jit, static_argnums=(1,))\n",
    "def nearest_neighbors(\n",
    "    x: jnp.array,\n",
    "    k: int,\n",
    "    mask: jnp.array = None,\n",
    "):\n",
    "    \"\"\"Returns the nearest neighbors of each node in x.\n",
    "\n",
    "    Args:\n",
    "        x (jnp.array): positions of nodes\n",
    "        k (int): number of nearest neighbors to find\n",
    "        boxsize (float, optional): size of box if perdioc boundary conditions. Defaults to None.\n",
    "        unit_cell (jnp.array, optional): unit cell for applying periodic boundary conditions. Defaults to None.\n",
    "        mask (jnp.array, optional): node mask. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        sources, targets: pairs of neighbors\n",
    "    \"\"\"\n",
    "    if mask is None:\n",
    "        mask = jnp.ones((x.shape[0],), dtype=np.int32)\n",
    "\n",
    "    n_nodes = x.shape[0]\n",
    "\n",
    "    # Compute the vector difference between positions\n",
    "    dr = x[:, None, :] - x[None, :, :]\n",
    "\n",
    "    # Calculate the distance matrix\n",
    "    distance_matrix = jnp.linalg.norm(dr, axis=-1)\n",
    "\n",
    "    distance_matrix = jnp.where(mask[:, None], distance_matrix, jnp.inf)\n",
    "    distance_matrix = jnp.where(mask[None, :], distance_matrix, jnp.inf)\n",
    "\n",
    "    indices = jnp.argsort(distance_matrix, axis=-1)[:, :k]\n",
    "\n",
    "    sources = indices[:, 0].repeat(k)\n",
    "    targets = indices.reshape(n_nodes * (k))\n",
    "\n",
    "    return sources, targets, dr[sources, targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.experimental.sparse import BCOO\n",
    "import dataclasses\n",
    "\n",
    "class DiffPool(nn.Module):\n",
    "    n_downsamples: int = 2  # Number of downsample layers\n",
    "    d_downsampling_factor: int = 4  # Downsampling factor at each layer\n",
    "    k: int = 10  # Number of nearest neighbors to consider after downsampling\n",
    "    gnn_kwargs: dict = dataclasses.field(default_factory=lambda: {\"d_hidden\":64, \"n_layers\":3})\n",
    "    symmetric: bool = True  # Symmetrize the adjacency matrix\n",
    "    task: str = \"node\"  # Node or graph task\n",
    "    combine_hierarchies_method: str = \"mean\"  # How to aggregate hierarchical embeddings; TODO: impl attention\n",
    "    use_edge_features: bool = False  # Whether to use edge features in adjacency matrix\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        \n",
    "        # If graph prediction task, collect pooled embeddings at each hierarchy level\n",
    "        if self.task == \"graph\":\n",
    "            x_pool = jnp.zeros((self.n_downsamples, self.gnn_kwargs['d_output']))\n",
    "\n",
    "        for i in range(self.n_downsamples):\n",
    "            \n",
    "            # Original and downsampled number of nodes\n",
    "            n_nodes = x.nodes.shape[0]\n",
    "            n_nodes_downsampled = n_nodes // self.d_downsampling_factor\n",
    "\n",
    "             # Eq. (5), graph embedding layer\n",
    "            z = GNN(task='node', **self.gnn_kwargs)(x) \n",
    "\n",
    "            # Eq. (6), generate assignment matrix\n",
    "            # Remove d_hidden from gnn_kwargs and replace it with n_nodes_downsampled\n",
    "            gnn_kwargs = dict(self.gnn_kwargs.copy())\n",
    "            gnn_kwargs['d_output'] = n_nodes_downsampled\n",
    "\n",
    "            s = GNN(task='node', **gnn_kwargs,)(x).nodes  \n",
    "            s = jax.nn.softmax(s, axis=1)  # Row-wise softmax\n",
    "            \n",
    "            # Sparse adjacency matrix\n",
    "            # If edge features, use them as weights, otherwise use 1 to indicate connectivity\n",
    "            edge_index = jnp.array([x.senders, x.receivers])\n",
    "            if self.use_edge_features:  \n",
    "                edge_weight = nn.Dense(1)(x.edges)[..., 0]  # Edges might have more than one feature; project down\n",
    "            else:\n",
    "                edge_weight = jnp.ones((x.edges.shape[0],))\n",
    "\n",
    "            a = BCOO((edge_weight, edge_index.T), shape=(n_nodes, n_nodes))\n",
    "            \n",
    "            # Eq. (3), coarsened node features\n",
    "            x = s.T @ z.nodes  \n",
    "            \n",
    "            # Eq. (4), coarsened adjacency matrix)\n",
    "            # Sparse matmul S^T @ A @ S\n",
    "            a = s.T @ a @ s  \n",
    "\n",
    "            # Make adj symmetric\n",
    "            if self.symmetric:\n",
    "                a = (a + a.T) / 2\n",
    "\n",
    "            # Take the coarsened adjacency matrix and make a KNN graph of it\n",
    "            indices = np.argsort(a, axis=-1)[:, :self.k]\n",
    "\n",
    "            sources = indices[:, 0].repeat(self.k)\n",
    "            targets = indices.reshape(n_nodes_downsampled * (self.k))\n",
    "\n",
    "            # Create new graph\n",
    "            x = jraph.GraphsTuple(\n",
    "                nodes=x,\n",
    "                edges=a[sources, targets][..., None],\n",
    "                senders=sources,\n",
    "                receivers=targets,\n",
    "                globals=None,\n",
    "                n_node=n_nodes_downsampled,\n",
    "                n_edge=self.k,\n",
    "            )\n",
    "\n",
    "            # If graph prediction task, get hierarchical embeddings\n",
    "            if self.task == \"graph\":\n",
    "                x_pool = x_pool.at[i].set(jnp.mean(x.nodes, axis=0))\n",
    "\n",
    "        if self.task == \"graph\":\n",
    "            if self.combine_hierarchies_method == \"mean\":  # Mean over hierarchy levels\n",
    "                x_pool = jnp.mean(x_pool, axis=0)\n",
    "            elif self.combine_hierarchies_method == \"concat\":  # Max over hierarchy levels\n",
    "                x_pool = jnp.concatenate(x_pool, axis=0)\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown combine_hierarchies_method: {self.combine_hierarchies_method}\")\n",
    "\n",
    "            return (x, x_pool)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "class DiffPoolWrapper(nn.Module):\n",
    "    model_kwargs: dict = dataclasses.field(default_factory=lambda: {})\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        return jax.vmap(DiffPool(**self.model_kwargs))(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original graph\n",
    "\n",
    "n_batch = 2\n",
    "k = 15\n",
    "\n",
    "sources, targets, distances = jax.vmap(nearest_neighbors, in_axes=(0, None))(x_train[:n_batch], k)\n",
    "\n",
    "graph = jraph.GraphsTuple(\n",
    "          n_node=np.array(n_batch * [[n_nodes]]), \n",
    "          n_edge=np.array(n_batch * [[k]]),\n",
    "          nodes=x_train[:n_batch, :, :], \n",
    "          edges=np.linalg.norm(distances, axis=-1)[..., None],\n",
    "          globals=None,\n",
    "          senders=sources,\n",
    "          receivers=targets)\n",
    "\n",
    "gnn_kwargs = {\"d_hidden\": 64, \"d_output\": 16, \"n_layers\": 2, \"message_passing_steps\":2}\n",
    "                 \n",
    "model = DiffPoolWrapper(model_kwargs={\"n_downsamples\": 4, \n",
    "                                \"d_downsampling_factor\": 4, \n",
    "                                \"k\": k,\n",
    "                                \"gnn_kwargs\": gnn_kwargs,\n",
    "                                \"combine_hierarchies_method\": 'mean',\n",
    "                                \"use_edge_features\": False,\n",
    "                                \"task\": 'graph'})\n",
    "\n",
    "rng = jax.random.PRNGKey(0)\n",
    "# rng = jax.random.split(rng, 1)\n",
    "(graph, x_pooled), params = model.init_with_output(rng, graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 477615\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of parameters:\", sum(p.size for p in jax.tree_util.tree_flatten(params)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We started with 4000 nodes and downsampled by a factor of 4 4 times, so we should have 15 nodes now.\n"
     ]
    }
   ],
   "source": [
    "print(f\"We started with {n_nodes} nodes and downsampled by a factor of {model.model_kwargs['d_downsampling_factor']} {model.model_kwargs['n_downsamples']} times, so we should have {n_nodes // model.model_kwargs['d_downsampling_factor'] ** model.model_kwargs['n_downsamples']} nodes now.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 15, 16)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.nodes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[ 0.37964916, -1.8670151 ,  0.5420827 , -3.4975605 , -1.0746057 ,\n",
       "        -0.5992161 ,  0.3162737 , -0.5658225 , -1.6766647 , -1.7225434 ,\n",
       "        -0.38327152,  2.1413724 ,  0.10378033,  0.41748714, -0.48726815,\n",
       "        -1.0837824 ],\n",
       "       [ 0.38148662, -1.8926976 ,  0.52135444, -3.5302162 , -1.0936382 ,\n",
       "        -0.64446616,  0.28737193, -0.5451107 , -1.6957139 , -1.7556255 ,\n",
       "        -0.37822193,  2.1825082 ,  0.09021281,  0.39656502, -0.48781922,\n",
       "        -1.122267  ]], dtype=float32)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_pooled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "equivariant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
