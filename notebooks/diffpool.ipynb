{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import flax.linen as nn\n",
    "import jraph\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from models.gnn import GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1800, 5000, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_nodes = 5000\n",
    "n_features = 3\n",
    "\n",
    "x_train = np.load(\"../../hierarchical-encdec/data/set_diffuser_data/train_halos.npy\")[:, :n_nodes, :n_features]\n",
    "x_train = x_train / 1000.\n",
    "\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@partial(jax.jit, static_argnums=(1,))\n",
    "def nearest_neighbors(\n",
    "    x: jnp.array,\n",
    "    k: int,\n",
    "    mask: jnp.array = None,\n",
    "):\n",
    "    \"\"\"Returns the nearest neighbors of each node in x.\n",
    "\n",
    "    Args:\n",
    "        x (jnp.array): positions of nodes\n",
    "        k (int): number of nearest neighbors to find\n",
    "        boxsize (float, optional): size of box if perdioc boundary conditions. Defaults to None.\n",
    "        unit_cell (jnp.array, optional): unit cell for applying periodic boundary conditions. Defaults to None.\n",
    "        mask (jnp.array, optional): node mask. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        sources, targets: pairs of neighbors\n",
    "    \"\"\"\n",
    "    if mask is None:\n",
    "        mask = jnp.ones((x.shape[0],), dtype=np.int32)\n",
    "\n",
    "    n_nodes = x.shape[0]\n",
    "\n",
    "    # Compute the vector difference between positions\n",
    "    dr = x[:, None, :] - x[None, :, :]\n",
    "\n",
    "    # Calculate the distance matrix\n",
    "    distance_matrix = jnp.linalg.norm(dr, axis=-1)\n",
    "\n",
    "    distance_matrix = jnp.where(mask[:, None], distance_matrix, jnp.inf)\n",
    "    distance_matrix = jnp.where(mask[None, :], distance_matrix, jnp.inf)\n",
    "\n",
    "    indices = jnp.argsort(distance_matrix, axis=-1)[:, :k]\n",
    "\n",
    "    sources = indices[:, 0].repeat(k)\n",
    "    targets = indices.reshape(n_nodes * (k))\n",
    "\n",
    "    return sources, targets, dr[sources, targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.experimental.sparse import BCOO\n",
    "import dataclasses\n",
    "\n",
    "class DiffPool(nn.Module):\n",
    "    n_downsamples: int = 2  # Number of downsample layers\n",
    "    d_downsampling_factor: int = 4  # Downsampling factor at each layer\n",
    "    k: int = 10  # Number of nearest neighbors to consider after downsampling\n",
    "    gnn_kwargs: dict = dataclasses.field(default_factory=lambda: {\"d_hidden\":64, \"n_layers\":3})\n",
    "    symmetric: bool = True  # Symmetrize the adjacency matrix\n",
    "    task: str = \"node\"  # Node or graph task\n",
    "    combine_hierarchies_method: str = \"mean\"  # How to aggregate hierarchical embeddings; TODO: impl attention\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        \n",
    "        # If graph prediction task, collect pooled embeddings at each hierarchy level\n",
    "        if self.task == \"graph\":\n",
    "            x_pool = jnp.zeros((self.n_downsamples, self.gnn_kwargs['d_hidden']))\n",
    "\n",
    "        for i in range(self.n_downsamples):\n",
    "            \n",
    "            # Original and downsampled number of nodes\n",
    "            n_nodes = x.nodes.shape[0]\n",
    "            n_nodes_downsampled = n_nodes // self.d_downsampling_factor\n",
    "\n",
    "             # Eq. (5), graph embedding layer\n",
    "            z = GNN(task='node', **self.gnn_kwargs)(x) \n",
    "\n",
    "            # Eq. (6), generate assignment matrix\n",
    "            # Remove d_hidden from gnn_kwargs and replace it with n_nodes_downsampled\n",
    "            gnn_kwargs = dict(self.gnn_kwargs.copy())\n",
    "            gnn_kwargs['d_hidden'] = n_nodes_downsampled\n",
    "\n",
    "            s = GNN(task='node', **gnn_kwargs,)(x).nodes  \n",
    "            s = jax.nn.softmax(s, axis=1)  # Row-wise softmax\n",
    "            \n",
    "            # Sparse adjacency matrix\n",
    "            edge_index = jnp.array([x.senders, x.receivers])\n",
    "            edge_weight = nn.Dense(1)(x.edges)[..., 0]  # Edges might have more than one feature; project down\n",
    "            a = BCOO((edge_weight, edge_index.T), shape=(n_nodes, n_nodes))\n",
    "            \n",
    "            # Eq. (3), coarsened node features\n",
    "            x = s.T @ z.nodes  \n",
    "            \n",
    "            # Eq. (4), coarsened adjacency matrix)\n",
    "            # Sparse matmul S^T @ A @ S\n",
    "            a = s.T @ a @ s  \n",
    "\n",
    "            # Make adj symmetric\n",
    "            if self.symmetric:\n",
    "                a = (a + a.T) / 2\n",
    "\n",
    "            # Take the coarsened adjacency matrix and make a KNN graph of it\n",
    "            indices = np.argsort(a, axis=-1)[:, :self.k]\n",
    "\n",
    "            sources = indices[:, 0].repeat(self.k)\n",
    "            targets = indices.reshape(n_nodes_downsampled * (self.k))\n",
    "\n",
    "            # Create new graph\n",
    "            x = jraph.GraphsTuple(\n",
    "                nodes=x,\n",
    "                edges=a[sources, targets][..., None],\n",
    "                senders=sources,\n",
    "                receivers=targets,\n",
    "                globals=None,\n",
    "                n_node=n_nodes_downsampled,\n",
    "                n_edge=self.k,\n",
    "            )\n",
    "\n",
    "            # If graph prediction task, get hierarchical embeddings\n",
    "            if self.task == \"graph\":\n",
    "                x_pool = x_pool.at[i].set(jnp.mean(x.nodes, axis=0))\n",
    "\n",
    "            \n",
    "        if self.task == \"graph\":\n",
    "            if self.combine_hierarchies_method == \"mean\":  # Mean over hierarchy levels\n",
    "                x_pool = jnp.mean(x_pool, axis=0)\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown combine_hierarchies_method: {self.combine_hierarchies_method}\")\n",
    "\n",
    "            return (x, x_pool)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original graph\n",
    "\n",
    "n_batch = 2\n",
    "k = 5\n",
    "\n",
    "sources, targets, distances = jax.vmap(nearest_neighbors, in_axes=(0, None))(x_train[:n_batch], k)\n",
    "\n",
    "graph = jraph.GraphsTuple(\n",
    "          n_node=np.array(n_batch * [[n_nodes]]), \n",
    "          n_edge=np.array(n_batch * [[k]]),\n",
    "          nodes=x_train[:n_batch, :, :], \n",
    "          edges=np.linalg.norm(distances, axis=-1)[..., None],\n",
    "          globals=None,\n",
    "          senders=sources,\n",
    "          receivers=targets)\n",
    "\n",
    "gnn_kwargs = {\"d_hidden\": 64, \"n_layers\": 2, \"message_passing_steps\":2}\n",
    "\n",
    "model = DiffPool(n_downsamples=4, \n",
    "                 d_downsampling_factor=4, \n",
    "                 k=k,\n",
    "                 gnn_kwargs=gnn_kwargs,\n",
    "                 task='graph')\n",
    "                 \n",
    "rng = jax.random.PRNGKey(0)\n",
    "(graph, x_pooled), params = jax.vmap(partial(model.init_with_output, rng))(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 33957702\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of parameters:\", sum(p.size for p in jax.tree_util.tree_flatten(params)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We started with 5000 nodes and downsampled by a factor of 4 4 times, so we should have 19 nodes now.\n"
     ]
    }
   ],
   "source": [
    "print(f\"We started with {n_nodes} nodes and downsampled by a factor of {model.d_downsampling_factor} {model.n_downsamples} times, so we should have {n_nodes // model.d_downsampling_factor**model.n_downsamples} nodes now.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 19, 64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.nodes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[-1.242315  ,  1.8907597 ,  0.18610084,  1.205286  ,  3.1136074 ,\n",
       "         0.45060843, -3.8228498 , -1.8208543 , -0.16492188, -2.5924544 ,\n",
       "         2.0409508 ,  0.8092485 ,  0.20801988, -0.23790902, -1.1132691 ,\n",
       "        -0.75181794,  2.2250085 ,  2.371746  , -3.9308715 , -0.77150047,\n",
       "         0.27231142, -0.4294128 , -2.1541467 ,  0.40734982, -1.6239084 ,\n",
       "        -0.51807344,  0.28549144, -1.336546  , -4.2158875 , -0.45217043,\n",
       "         2.1452994 , -2.9813814 , -2.0238123 , -1.9766072 ,  1.7757881 ,\n",
       "         2.8210025 ,  0.32308742,  4.198517  ,  0.9147968 ,  0.88743   ,\n",
       "        -1.1192008 ,  0.45856455,  0.6381138 ,  2.7762437 , -1.9243879 ,\n",
       "        -1.5166618 , -0.8365273 , -1.9778895 ,  1.14055   ,  0.64505357,\n",
       "        -1.1686766 , -1.526515  ,  0.7428796 , -0.8848613 , -2.8648953 ,\n",
       "         4.2006307 , -0.72397524,  1.0264693 , -0.41371283,  1.8388839 ,\n",
       "         1.6259108 ,  1.7044799 ,  3.1721783 ,  0.61579967],\n",
       "       [-1.239231  ,  1.9008791 ,  0.20033514,  1.203122  ,  3.0952833 ,\n",
       "         0.44131404, -3.8269267 , -1.8166693 , -0.17275023, -2.5888505 ,\n",
       "         2.0378711 ,  0.80033994,  0.20700324, -0.2366119 , -1.1252191 ,\n",
       "        -0.75556123,  2.2355661 ,  2.37351   , -3.921178  , -0.76823974,\n",
       "         0.27151802, -0.42465824, -2.129377  ,  0.4150948 , -1.6355208 ,\n",
       "        -0.5103053 ,  0.28432912, -1.3337867 , -4.2133536 , -0.4603809 ,\n",
       "         2.1345909 , -2.9943092 , -2.0163012 , -1.9776118 ,  1.7788452 ,\n",
       "         2.8196473 ,  0.31086832,  4.212395  ,  0.92120963,  0.8818981 ,\n",
       "        -1.1305771 ,  0.46477604,  0.6457791 ,  2.7785234 , -1.9204574 ,\n",
       "        -1.5273101 , -0.8469968 , -1.973294  ,  1.1463833 ,  0.647163  ,\n",
       "        -1.1499352 , -1.5216401 ,  0.7359369 , -0.88857126, -2.8600192 ,\n",
       "         4.186345  , -0.7136469 ,  1.0096909 , -0.43258286,  1.8459784 ,\n",
       "         1.6265676 ,  1.7071178 ,  3.185185  ,  0.60685116]],      dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_pooled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "equivariant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
